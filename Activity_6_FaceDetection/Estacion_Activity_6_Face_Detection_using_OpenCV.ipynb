{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj9Q5rZAFAlM"
      },
      "source": [
        "| Technological Institute of the Philippines | Quezon City - Computer Engineering                                      |\n",
        "| ------------------------------------------ | ----------------------------------------------------------------------- |\n",
        "| Course Code:                               | CPE 313                                                                 |\n",
        "| Code Title:                                | Advanced Machine Learning and Deep Learning                             |\n",
        "| 1st Semester                               | AY 2023-2024                                                            |\n",
        "| <hr>                                       | <hr>                                                                    |\n",
        "| <u>**ACTIVITY NO.**                        | **TITLE**                                                               |\n",
        "| **Name**                                   | Estacion, Kenneth                                                       |\n",
        "| **Section**                                | CPE32S8                                                                 |\n",
        "| **Date Performed**:                        | Feb. 20, 2024                                                           |\n",
        "| **Date Submitted**:                        | Feb. 22, 2024                                                           |\n",
        "| **Instructor**:                            | Dr. Jonathan V. Taylar / Engr. Verlyn V. Nojor / Engr. Roman M. Richard |\n",
        "\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElMxAUPJGYLw"
      },
      "source": [
        "## 1. Objectives\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr0bUEs1nxE0"
      },
      "source": [
        "This activity aims to allow students to perform face detection on still images and videos using Haar cascades.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do-8nSpXFpyd"
      },
      "source": [
        "## 2. Intended Learning Outcomes (ILOs)\n",
        "\n",
        "After this activity, the students should be able to:\n",
        "\n",
        "- Utilize OpenCV to detect faces in still images and videos.\n",
        "- Demonstrate the use of Haar-like features for detection of other human features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-RNZovNGV9k"
      },
      "source": [
        "## 3. Procedures and Outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NzR4JDbiyDg"
      },
      "source": [
        "Contrary to initial assumptions, conducting face detection on a static image and a video stream shares a remarkable similarity. Essentially, the latter is merely a sequential rendition of the former: when detecting faces in videos, it essentially involves applying face detection to every individual frame obtained from the camera feed. Of course, video face detection introduces additional elements like tracking, which aren't relevant to static images. Nevertheless, it's valuable to recognize that the fundamental principles behind both processes remain consistent.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1gC-lR2izhw"
      },
      "source": [
        "### Performing face detection on still image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMLyshf2izdI"
      },
      "source": [
        "The first and most basic way to perform face detection is to load an image and detect faces in it. To make the result visually meaningful, we will draw rectangles around faces on the original image.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkwbbeEAoPlw"
      },
      "source": [
        "**Before implementing the code below**, check the contents of the `cv2.CascadeClassifier()` function. Provide an explanation of the function, its parameters before running the code below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "c4TmUw_BEeUc"
      },
      "outputs": [],
      "source": [
        "# Make sure that for this activity, you have downloaded the\n",
        "# file indicated below from the resource linked in the instructional materials\n",
        "# in the module.\n",
        "\n",
        "import cv2\n",
        "main_path = 'Activity_6_FaceDetection/'\n",
        "picPath = 'breakingbad.jpg'\n",
        "haarPath = main_path+'haarcascade_frontalface_default.xml'\n",
        "def faceDetect(picPath):\n",
        "  face_cascade = cv2.CascadeClassifier(haarPath)\n",
        "\n",
        "  img = cv2.imread(picPath)\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "  for (x, y, w, h) in faces:\n",
        "    img = cv2.rectangle(img, (x, y), (x+w, y+h), (255,0,0), 2)\n",
        "\n",
        "  cv2.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "img = cv2.imread(picPath)\n",
        "cv2.imshow('Breaking Bad',img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "print(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "iMDiBHDHn0qw",
        "outputId": "529a3dbd-2533-4c3d-dac0-29d00131c115"
      },
      "outputs": [
        {
          "ename": "error",
          "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m faceDetect(picPath)\n",
            "Cell \u001b[1;32mIn[9], line 14\u001b[0m, in \u001b[0;36mfaceDetect\u001b[1;34m(picPath)\u001b[0m\n\u001b[0;32m     11\u001b[0m face_cascade \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mCascadeClassifier(haarPath)\n\u001b[0;32m     13\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(picPath)\n\u001b[1;32m---> 14\u001b[0m gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcvtColor(img, cv2\u001b[39m.\u001b[39;49mCOLOR_BGR2GRAY)\n\u001b[0;32m     15\u001b[0m faces \u001b[39m=\u001b[39m face_cascade\u001b[39m.\u001b[39mdetectMultiScale(gray, \u001b[39m1.3\u001b[39m, \u001b[39m5\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m (x, y, w, h) \u001b[39min\u001b[39;00m faces:\n",
            "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
          ]
        }
      ],
      "source": [
        "faceDetect(picPath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QKfV7ANos6O"
      },
      "source": [
        "**Analysis**:\n",
        "\n",
        "- Based on your earlier analysis, where do you think the face detection works in the line of code above?\n",
        "- Provide an analysis of the parameters of the `detectMultiScale` method.\n",
        "- Change the color of the border of the detected faces to red.\n",
        "- Are you able to make the borders thicker? Demonstrate.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yap3yT5PsO8Q"
      },
      "source": [
        "### Performing face detection on video\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZbxG6gBphzF"
      },
      "source": [
        "**Step 1**: Create a file called face_detection.py and include the following codes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tBVolHTcGoCo"
      },
      "outputs": [],
      "source": [
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WboZyA6lpk81"
      },
      "source": [
        "**Step 2:** After this, we declare a method, `detect()`, which will perform face detection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RHorhmfopnvV"
      },
      "outputs": [],
      "source": [
        "def detect():\n",
        "  face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "  eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
        "  camera = cv2.VideoCapture(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W4p9q1OqYP0"
      },
      "source": [
        "**Step 3:** The first thing we need to do inside the detect() method is to load the Haar cascade files so that OpenCV can operate face detection. As we copied\n",
        "the cascade files in the local `cascades/` folder, we can use a relative path. Then, we open a VideoCapture object (the camera feed). The VideoCapture constructor takes a parameter, which indicates the camera to be used; zero indicates the first camera available.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vVGMXB7rjPT"
      },
      "outputs": [],
      "source": [
        "  while (True):\n",
        "    ret, frame = camera.read()\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zieVeRN_rlxa"
      },
      "source": [
        "**Step 4:** Next up, we capture a frame. The read() method returns two values: a Boolean indicating the success of the frame read operation, and the frame\n",
        "itself. We capture the frame, and then we convert it to grayscale. This is a necessary operation, because face detection in OpenCV happens in the grayscale color space:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_LBk8P-r36S"
      },
      "outputs": [],
      "source": [
        "faces = face_cascade.detectMultiScale(gray, 1.3, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9K3VPUQRr7ii"
      },
      "source": [
        "**Step 5:** Much like the single still image example, we call detectMultiScale on the grayscale version of the frame.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELwHm8NqsAIp"
      },
      "outputs": [],
      "source": [
        "  for (x,y,w,h) in faces:\n",
        "    img = cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "    roi_gray = gray[y:y+h, x:x+w]\n",
        "    eyes = eye_cascade.detectMultiScale(roi_gray, 1.03,\n",
        "    5, 0, (40,40))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MA68hKlse7I"
      },
      "source": [
        "**Step 6:** Here we have a further step compared to the still image example: we create a region of interest corresponding to the face rectangle, and within this rectangle, we operate \"eye detection\". This makes sense as you wouldn't want to go looking for eyes outside a face (well, for human beings at least!).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9V5PPcfsjpX"
      },
      "outputs": [],
      "source": [
        "  for (ex,ey,ew,eh) in eyes:\n",
        "    cv2.rectangle(img,(ex,ey),(ex+ew,ey+eh),\n",
        "    (0,255,0),2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzqjveHPspQ3"
      },
      "source": [
        "**Step 7:** Again, we loop through the resulting eye tuples and draw green rectangles around them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJlmIIERso0w"
      },
      "outputs": [],
      "source": [
        "\n",
        "    cv2.imshow(\"camera\", frame)\n",
        "    if cv2.waitKey(1000 / 12) & 0xff == ord(\"q\"):\n",
        "      break\n",
        "\n",
        "  camera.release()\n",
        "  cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "detect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI59-kERsyxP"
      },
      "source": [
        "**Provide the following**:\n",
        "\n",
        "- Screenshot of the output for the working code once you've put it all together.\n",
        "- Summary of the steps you've performed along with observations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkyd0KjtGl79"
      },
      "source": [
        "## 4. Supplementary Activity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLjTzJoxpT-N"
      },
      "source": [
        "In your Cameo project, include real-time face detection using Haar cascade. Show screenshots of the working demonstration for this supplementary activity.\n",
        "\n",
        "Additionally, implement similar steps to detect a smile using Haar cascades.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQspxP0IGoO1"
      },
      "source": [
        "## 5. Summary, Conclusions and Lessons Learned\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvcmGICAoj1a"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqlVIPSqolAC"
      },
      "source": [
        "<hr/>\n",
        "\n",
        "**_Proprietary Clause_**\n",
        "\n",
        "_Property of the Technological Institute of the Philippines (T.I.P.). No part of the materials made and uploaded in this learning management system by T.I.P. may be copied, photographed, printed, reproduced, shared, transmitted, translated, or reduced to any electronic medium or machine-readable form, in whole or in part, without the prior consent of T.I.P._\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Mkyd0KjtGl79",
        "KQspxP0IGoO1"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
